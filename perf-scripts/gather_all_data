#!/usr/bin/env python3

"""
Gather all performance data on all platforms of interest and store
them in a git branch.

It is expected that you are able to do a passwordless ssh to all
machines and that the given repo on the target machines are clean.
Since testbeds do not allow login via ssh key, you'll need to use kinit.
Waterman is on the SRN, so you'll need to start from a SRN machine. I've
had good luck using face.sandia.gov as my launch machine.

It is expected that your current repo is clean and that your current commit
is the one you want to test.
"""

from utils import run_cmd_no_fail, expect, check_minimum_python_version, get_current_commit
check_minimum_python_version(3, 5)

import argparse, sys, os
import concurrent.futures as threading3

# MACHINE -> (modules, repo-loc, kokkos-install-loc, compiler, batch submit prefix)
MACHINE_METADATA = {
    "bowman"   : (["openmpi/1.10.6/intel/17.2.174", "git/2.8.2",  "cmake/3.5.2"],                        "$HOME/kokkos-install-bowman/install", "$(which mpicxx)", "srun"),
    "blake"    : (["openmpi/2.1.5/intel/19.1.144", "git/2.9.4",  "cmake/3.9.0"],                         "$HOME/kokkos-install-blake/install",  "$(which mpicxx)", "srun"),
    "waterman" : (["devpack/latest/openmpi/2.1.2/gcc/7.2.0/cuda/9.2.88", "git/2.10.1", "cmake/3.9.6"],   "$HOME/kokkos-install/install",        "$(which mpicxx)", "bsub -I -q rhel7W"),
    "white"    : (["devpack/20181011/openmpi/2.1.2/gcc/7.2.0/cuda/9.2.88", "git/2.10.1", "cmake/3.9.6"], "$HOME/kokkos-install-white/install",  "$(which mpicxx)", "bsub -I -q rhel7G"),
}

###############################################################################
def parse_command_line(args, description):
###############################################################################
    parser = argparse.ArgumentParser(
        usage="""\n{0} <PERF-ANALYSIS-ARGS> [--verbose]
OR
{0} --help

\033[1mEXAMPLES:\033[0m
    \033[1;32m# Gather data \033[0m
    > {0} '64 128 300 30 10 $kokkos_install --cxx=$compiler -s "ni:2.0:16384" -n 10'
    # NOTE: leave the variables in the args unresolved so the script can resolve them

    \033[1;32m# Gather data for specific tests and specific machines \033[0m
    > {0} '64 128 300 30 10 $kokkos_install --cxx=$compiler -t ref -t final -s "ni:2.0:16384" -n 10' -m waterman -m bowman

    \033[1;32m# Do correctness testing instead of performance testing \033[0m
    > {0} '' -t
""".format(os.path.basename(args[0])),
        description=description,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument("perf_analysis_args", help="Args to pass to perf_analysis")

    default_commit = get_current_commit(short=True)
    parser.add_argument("-c", "--commit", default=default_commit, help="Commit to test")

    parser.add_argument("-m", "--machine", action="append", choices=MACHINE_METADATA.keys(),
                        help="Select which machines to run on, default is all")

    parser.add_argument("-t", "--test-all", action="store_true", help="Run test-all instead of performance gathering")

    parser.add_argument("-s", "--scream", action="store_true", help="Test scream instead of scream-docs. Implies --test-all")

    args = parser.parse_args(args[1:])

    if args.scream:
        expect(os.path.basename(os.getcwd()) == "scream", "Please run from components/scream directory")
    else:
        expect(os.path.basename(os.getcwd()) == "micro-apps", "Please run from micro-apps directory")

    if not args.machine:
        args.machine = MACHINE_METADATA.keys()

    if args.scream:
        args.test_all = True

    return args.perf_analysis_args, args.commit, args.machine, args.test_all, args.scream

###############################################################################
def formulate_command(machine, perf_analysis_args, commit, test_all, scream):
###############################################################################
    modules, kokkos, compiler, batch = MACHINE_METADATA[machine]

    scream_docs_repo = "~/scream-docs-perf-{}/micro-apps".format(machine)
    repo             = "~/scream-perf-{}/components/scream".format(machine) if scream else scream_docs_repo

    local_cmd = "{}/test-all {} {}".format(scream_docs_repo, compiler, kokkos) if test_all else "../perf-scripts/perf_analysis {} -p".format(perf_analysis_args)
    local_cmd = local_cmd.replace("$compiler", compiler).replace("$kokkos_install", kokkos)

    setup = "cd {} && git fetch && git reset --hard origin/master && ".format(scream_docs_repo) if scream else ""
    extra_env = ""
    if machine in ["waterman", "white"]:
        extra_env = "OMPI_CXX={}/bin/nvcc_wrapper ".format(kokkos)

    cmd = "{}cd {} && module load {} && git fetch && git checkout {} && {}{} {}".format(setup, repo, " ".join(modules), commit, extra_env, batch, local_cmd)

    return cmd

###############################################################################
def run_on_machine(machine, perf_analysis_args, commit, test_all, scream):
###############################################################################
    cmd = formulate_command(machine, perf_analysis_args, commit, test_all, scream)
    print("Starting {} analysis on {} with cmd: {}".format("test-all" if test_all else "performance", machine, cmd))

    output = run_cmd_no_fail("ssh -o StrictHostKeyChecking=no {} '{}'".format(machine, cmd), exc_type=RuntimeError)
    with open(os.path.join("test-all-results" if test_all else "perf-results", commit, machine), "w") as fd:
        fd.write(output)

    print ("Completed {} analysis on {}".format("test-all" if test_all else "performance", machine))

###############################################################################
def gather_all_data(perf_analysis_args, commit, machines, test_all, scream):
###############################################################################
    os.makedirs(os.path.join("test-all-results" if test_all else "perf-results", commit))

    success = True

    with threading3.ThreadPoolExecutor(max_workers=len(machines)) as executor:
        future_to_machine = {executor.submit(run_on_machine, machine, perf_analysis_args, commit, test_all, scream): machine for machine in machines}
        for future in threading3.as_completed(future_to_machine):
            machine = future_to_machine[future]
            try:
                future.result()
            except Exception as exc:
                print('{} failed with exception: {}'.format(machine, exc))
                success = False

    return success

###############################################################################
def _main_func(description):
###############################################################################
    perf_analysis_args, commit, machines, test_all, scream = parse_command_line(sys.argv, description)

    success = gather_all_data(perf_analysis_args, commit, machines, test_all, scream)

    sys.exit(0 if success else 1)

###############################################################################

if (__name__ == "__main__"):
    _main_func(__doc__)
